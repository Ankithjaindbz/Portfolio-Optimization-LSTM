# -*- coding: utf-8 -*-
"""Untitled28.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y_ZIid0PUrDuZs1mAqyr1opTz_H0LtjV

#Stock Price Forecasting

Utilizes LSTM (Long Short-Term Memory) neural networks for time series prediction
Implements feature engineering to enhance model performance
Employs Keras Tuner for hyperparameter optimization
"""

!pip install keras-tuner
!pip install ta
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from pandas.tseries.offsets import BDay
import yfinance as yf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import keras_tuner as kt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
from sklearn.model_selection import train_test_split
import ta

# Define functions for feature engineering
def add_log_features(df):
    for i in range(1, 5):
        df[f'Log_Close_{i}'] = np.log(df['Close'] / df['Close'].shift(i))
    for i in range(4):
        df[f'Log_High_Open_{i}'] = np.log(df['High'] / df['Open'].shift(i))
    df.dropna(inplace=True)
    return df

def add_moving_averages(df):
    df['EMA_9'] = df['Close'].ewm(span=9).mean().shift()
    for span in [5, 10, 15, 20, 25, 30]:
        df[f'SMA_{span}'] = df['Close'].rolling(span).mean().shift()
    df.dropna(inplace=True)
    return df

def add_technical_indicators(df):
    df['RSI_14'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()
    macd = ta.trend.MACD(df['Close'])
    df['MACD'] = macd.macd()
    df['MACD_Signal'] = macd.macd_signal()
    df['MACD_Diff'] = macd.macd_diff()
    df['ATR_14'] = ta.volatility.AverageTrueRange(df['High'], df['Low'], df['Close'], window=14).average_true_range()
    df.dropna(inplace=True)
    return df

def add_more_features(df):
    df['SMA_50'] = df['Close'].rolling(window=50).mean()
    df['SMA_200'] = df['Close'].rolling(window=200).mean()
    df['Volatility'] = df['Close'].rolling(window=30).std()
    df.dropna(inplace=True)
    return df

# Fetch data from Yahoo Finance
# Fetch data from Yahoo Finance
stock_symbol = 'ITC.NS'
df = yf.download(stock_symbol, start='2011-12-01', end='2023-12-1')
df.reset_index(inplace=True)  # This converts the index to a column


# Apply feature engineering functions
df = add_log_features(df)
df = add_moving_averages(df)
df = add_technical_indicators(df)
df = add_more_features(df)

# Define features for the model
features = [
    'Close', 'EMA_9', 'SMA_5', 'SMA_10', 'SMA_15', 'SMA_20', 'SMA_25', 'SMA_30',
    'Log_Close_1', 'Log_Close_2', 'Log_Close_3', 'Log_Close_4',
    'Log_High_Open_0', 'Log_High_Open_1', 'Log_High_Open_2', 'Log_High_Open_3',
    'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Diff', 'ATR_14', 'SMA_50', 'SMA_200', 'Volatility'
]

df_for_training = df[features].astype(float)

# Scale the features
scaler = StandardScaler()
df_for_training_scaled = scaler.fit_transform(df_for_training)

# Prepare data for LSTM model
trainX = []
trainY = []
n_future = 1
n_past = 14

for i in range(n_past, len(df_for_training_scaled) - n_future + 1):
    trainX.append(df_for_training_scaled[i - n_past:i, :])
    trainY.append(df_for_training_scaled[i + n_future - 1, 0])

trainX, trainY = np.array(trainX), np.array(trainY)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.2, shuffle=False)

# Define the model building function for Keras Tuner
def build_model(hp):
    model = Sequential()
    model.add(LSTM(units=hp.Int('units_1', min_value=32, max_value=192, step=32),
                   activation='relu', return_sequences=True,
                   input_shape=(trainX.shape[1], trainX.shape[2])))
    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.3, step=0.1)))
    model.add(LSTM(units=hp.Int('units_2', min_value=32, max_value=192, step=32),
                   activation='relu'))
    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.3, step=0.1)))
    model.add(Dense(1))
    model.compile(optimizer='adam',
                  loss='mean_squared_error',
                  metrics=['mean_absolute_error', 'mean_squared_error'])
    return model

# Set up Keras Tuner for hyperparameter optimization
TUNER_DIRECTORY = f'ktuner_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
tuner = kt.RandomSearch(build_model,
                        objective='val_mean_absolute_error',
                        max_trials=5,
                        executions_per_trial=1,
                        directory=TUNER_DIRECTORY,
                        project_name='stock_prediction')

# Add EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Perform the hyperparameter search
tuner.search(X_train, y_train, epochs=150, validation_split=0.2, callbacks=[early_stopping])

# Get the best model
best_model = tuner.get_best_models(num_models=1)[0]
best_model.summary()

# Make predictions on the test set
predictions_test = best_model.predict(X_test)

# Calculate performance metrics
mae_test = mean_absolute_error(y_test, predictions_test)
mse_test = mean_squared_error(y_test, predictions_test)
r2_test = r2_score(y_test, predictions_test)
mape_test = mean_absolute_percentage_error(y_test, predictions_test)

print(f'Testing Set Metrics - MAE: {mae_test}, MSE: {mse_test}, R2: {r2_test}, MAPE: {mape_test}')

# Assuming 'future_predictions' holds the predicted values for one feature (e.g., 'Close')

# Construct a dummy array with the same number of features as during scaling
# Fill the array with zeros except for the feature that was predicted
full_features_dummy = np.zeros((len(future_predictions), len(features)))
full_features_dummy[:, 0] = future_predictions  # Assuming 'Close' is the first feature

# Now apply the inverse transformation
predicted_close_prices = scaler.inverse_transform(full_features_dummy)[:, 0]  # Extract only the 'Close' prices

# Generate the dates for the predictions
last_known_date = df['Date'].iloc[-1]
predict_dates = pd.date_range(start=last_known_date + pd.Timedelta(days=1), periods=len(future_predictions), freq='B')

# Create a DataFrame to store the predicted prices with their corresponding dates
df_forecast = pd.DataFrame(data={'Date': predict_dates, 'Predicted Close': predicted_close_prices})

# Display the forecast
print(df_forecast)

# Plotting the predictions
plt.figure(figsize=(10, 5))
plt.plot(df['Date'], df['Close'], label='Historical Daily Close Price')
plt.plot(df_forecast['Date'], df_forecast['Predicted Close'], 'r--', label='Forecasted Daily Close Price')
plt.title('Future Stock Prices Prediction')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

# Save the forecast to a CSV file
forecast_csv_path = f'forecast_{stock_symbol}_30_days.csv'
df_forecast.to_csv(forecast_csv_path, index=False)
print(f"Forecast saved to {forecast_csv_path}")

"""#Portfolio Optimization via Monte Carlo Simulation

Generates thousands of portfolio combinations
Calculates key metrics like Sharpe ratio, Value at Risk (VaR), and Conditional Value at Risk (CVaR)
Identifies the optimal portfolio weights based on the highest Sharpe ratio
"""

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/forecast_ITC.NS_30_days.csv')
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# Calculate daily returns
returns = data.pct_change().dropna()

# Set parameters for Monte Carlo simulation
num_simulations = 100000
num_days = 252  # Approximately one trading year

# Set random seed for reproducibility
np.random.seed(42)

# Perform Monte Carlo simulation for each stock
simulation_results = {}
for stock in returns.columns:
    mean_return = returns[stock].mean()
    std_return = returns[stock].std()

    # Simulate stock prices
    simulated_paths = np.zeros((num_days, num_simulations))
    simulated_paths[0] = data[stock].iloc[-1]
    for t in range(1, num_days):
        random_returns = np.random.normal(mean_return, std_return, num_simulations)
        simulated_paths[t] = simulated_paths[t-1] * (1 + random_returns)

    simulation_results[stock] = simulated_paths

# Calculate portfolio metrics
num_portfolios = 100000
results = np.zeros((4, num_portfolios))
weights_record = []

for i in range(num_portfolios):
    # Generate random weights
    weights = np.random.random(len(returns.columns))
    weights /= np.sum(weights)
    weights_record.append(weights)

    # Calculate portfolio return and risk
    portfolio_return = np.sum(returns.mean() * weights) * 252
    portfolio_stddev = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))
    sharpe_ratio = portfolio_return / portfolio_stddev

    # Store results
    results[0, i] = portfolio_return
    results[1, i] = portfolio_stddev
    results[2, i] = sharpe_ratio
    results[3, i] = np.sum(weights > 0)

# Find the optimal portfolio (highest Sharpe ratio)
max_sharpe_idx = np.argmax(results[2])
optimal_weights = weights_record[max_sharpe_idx]
optimal_portfolio_return = results[0, max_sharpe_idx]
optimal_portfolio_stddev = results[1, max_sharpe_idx]
optimal_sharpe_ratio = results[2, max_sharpe_idx]
optimal_cardinality = results[3, max_sharpe_idx]

# Calculate portfolio metrics
one_day_return = np.sum(returns.mean() * optimal_weights)
annualized_return = optimal_portfolio_return
sharpe_ratio = optimal_sharpe_ratio
daily_volatility = np.sqrt(np.dot(optimal_weights.T, np.dot(returns.cov(), optimal_weights)))
annual_volatility = daily_volatility * np.sqrt(252)

# Get the stock names
stock_names = returns.columns

# Map stock names to their weights in the optimal portfolio
optimal_weights_dict = dict(zip(stock_names, optimal_weights))

# Print the results
print("Optimal Portfolio Cardinality:", optimal_cardinality)
print("One-day Return of the Portfolio:", one_day_return)
print("Annualized Return of the Portfolio:", annualized_return)
print("Sharpe Ratio of the Portfolio:", sharpe_ratio)
print("Daily Volatility of the Portfolio:", daily_volatility)
print("Annual Volatility of the Portfolio:", annual_volatility)
print("Weights of the Stocks in the Optimal Portfolio:")
for stock, weight in optimal_weights_dict.items():
    print(f"{stock}: {weight:.4f}")

# Monte Carlo simulation for the portfolio based on optimal weights
portfolio_simulation = np.zeros((num_days, num_simulations))
initial_portfolio_value = data.iloc[-1].dot(optimal_weights)
portfolio_simulation[0] = initial_portfolio_value

for t in range(1, num_days):
    random_returns = np.random.multivariate_normal(returns.mean(), returns.cov(), num_simulations)
    portfolio_simulation[t] = portfolio_simulation[t-1] * (1 + np.dot(random_returns, optimal_weights))

# Plot the simulation results for the portfolio
plt.figure(figsize=(10, 6))
plt.plot(portfolio_simulation, lw=0.5, alpha=0.1, color='green')
plt.title('Monte Carlo Simulation for the Portfolio')
plt.xlabel('Days')
plt.ylabel('Portfolio Value')
plt.show()

# Calculate Value at Risk (VaR) at the 95% confidence level
confidence_level = 0.95
VaR = np.percentile(portfolio_simulation[-1], (1 - confidence_level) * 100)
print(f"Value at Risk (VaR) at {confidence_level * 100}% confidence level: {VaR:.2f}")

# Calculate Conditional Value at Risk (CVaR) at the 95% confidence level
tail_losses = portfolio_simulation[-1, portfolio_simulation[-1] <= VaR]
CVaR = tail_losses.mean()
print(f"Conditional Value at Risk (CVaR) at {confidence_level * 100}% confidence level: {CVaR:.2f}")

# Plot histogram of final portfolio values
plt.figure(figsize=(10, 6))
plt.hist(portfolio_simulation[-1], bins=50, alpha=0.75, color='blue', edgecolor='black')
plt.title('Distribution of Final Portfolio Values')
plt.xlabel('Final Portfolio Value')
plt.ylabel('Frequency')
plt.axvline(VaR, color='r', linestyle='dashed', linewidth=2, label=f'VaR: {VaR:.2f}')
plt.axvline(CVaR, color='g', linestyle='dashed', linewidth=2, label=f'CVaR: {CVaR:.2f}')
plt.legend()
plt.show()
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Define the stocks and their respective weights in the portfolio
weights = {
    "RELIANCE.NS": 0.15, "TCS.NS": 0.10, "INFY.NS": 0.10, "HDFCBANK.NS": 0.10,
    "ICICIBANK.NS": 0.08, "HINDUNILVR.NS": 0.07, "SBIN.NS": 0.07, "BAJFINANCE.NS": 0.07,
    "BHARTIARTL.NS": 0.06, "ITC.NS": 0.05, "LT.NS": 0.05, "AXISBANK.NS": 0.04,
    "ONGC.NS": 0.03, "SUNPHARMA.NS": 0.03, "WIPRO.NS": 0.02
}
# Initial investment
initial_investment = 100000

# Download historical data for the stocks and the Dow Jones Industrial Average as a benchmark
tickers = list(weights.keys()) + ['^DJI']
data = yf.download(tickers, start="2021-8-1", end="2024-8-1")['Adj Close']

# Separate the benchmark data
benchmark_data = data.pop('^DJI')

# Calculate daily returns for the stocks and the benchmark
returns = data.pct_change()
benchmark_returns = benchmark_data.pct_change()

# Calculate portfolio daily returns
portfolio_daily_returns = (returns * pd.Series(weights)).sum(axis=1)

# Calculate cumulative portfolio returns and benchmark returns
cumulative_portfolio_returns = (1 + portfolio_daily_returns).cumprod()
cumulative_benchmark_returns = (1 + benchmark_returns).cumprod()

# Calculate final portfolio value and benchmark value
final_portfolio_value = initial_investment * cumulative_portfolio_returns
final_benchmark_value = initial_investment * cumulative_benchmark_returns

# Calculate annual returns and Sharpe ratio for both portfolio and benchmark
annual_returns = portfolio_daily_returns.resample('Y').apply(lambda x: (1 + x).prod() - 1)
annual_benchmark_returns = benchmark_returns.resample('Y').apply(lambda x: (1 + x).prod() - 1)
annual_volatility = portfolio_daily_returns.resample('Y').std() * np.sqrt(252)
annual_benchmark_volatility = benchmark_returns.resample('Y').std() * np.sqrt(252)
risk_free_rate = 0.03  # Assume a risk-free rate of 3%
annual_sharpe_ratios = (annual_returns - risk_free_rate) / annual_volatility
annual_benchmark_sharpe = (annual_benchmark_returns - risk_free_rate) / annual_benchmark_volatility

# Calculate Beta and Alpha for the portfolio
covariance = np.cov(portfolio_daily_returns[1:], benchmark_returns[1:])
beta = covariance[0, 1] / covariance[1, 1]
alpha = annual_returns.mean() - (risk_free_rate + beta * (annual_benchmark_returns.mean() - risk_free_rate))

# Calculate and print excess returns for holding periods of 1, 2, 3, 4, and 5 years
holding_periods = [1, 2, 3, 4, 5]

for period in holding_periods:
    if len(final_portfolio_value) > period * 252:
        portfolio_period_return = final_portfolio_value[-1] / final_portfolio_value[-(period * 252)] - 1
        benchmark_period_return = final_benchmark_value[-1] / final_benchmark_value[-(period * 252)] - 1
        excess_return = portfolio_period_return - benchmark_period_return
        print(f"{period}-year Holding Period: Portfolio Return: {portfolio_period_return * 100:.2f}%, Benchmark Return: {benchmark_period_return * 100:.2f}%, Excess Return: {excess_return * 100:.2f}%")

# Print annual metrics for portfolio and benchmark
print("\nAnnual Returns and Sharpe Ratios:")
for year in sorted(annual_returns.index.year):
    print(f"{year} - Portfolio Return: {annual_returns[str(year)].mean() * 100:.2f}%, Sharpe Ratio: {annual_sharpe_ratios[str(year)].mean():.2f}")
    print(f"{year} - Benchmark Return: {annual_benchmark_returns[str(year)].mean() * 100:.2f}%, Sharpe Ratio: {annual_benchmark_sharpe[str(year)].mean():.2f}")

# Extract date range for plotting
start_date = final_portfolio_value.index.min().strftime('%Y-%m-%d')
end_date = final_portfolio_value.index.max().strftime('%Y-%m-%d')

# Plot both the portfolio and benchmark growth over time
plt.figure(figsize=(14, 7))
plt.plot(final_portfolio_value, label='Portfolio Value')
plt.plot(final_benchmark_value, color='red', label='DJI Index')
plt.title(f'Portfolio and Benchmark Value Over Time\n({start_date} to {end_date})')
plt.xlabel('Date')
plt.ylabel('Value in $')
plt.legend()
plt.grid(True)
plt.show()

# Calculate and print the final Sharpe ratio of the portfolio
final_annual_return = (final_portfolio_value[-1] / initial_investment) ** (1 / (len(final_portfolio_value) / 252)) - 1
final_annual_volatility = portfolio_daily_returns.std() * np.sqrt(252)
final_sharpe_ratio = (final_annual_return - risk_free_rate) / final_annual_volatility

# Print portfolio and benchmark metrics
print("\nPortfolio vs. Benchmark Metrics:")
print(f"Portfolio Beta: {beta:.2f}")
print(f"Portfolio Alpha: {alpha * 100:.2f}%")
print(f"Final portfolio value (end of period): ${final_portfolio_value.iloc[-1]:,.2f}")
print(f"Final benchmark value (end of period): ${final_benchmark_value.iloc[-1]:,.2f}")
print(f"Final Portfolio Sharpe Ratio: {final_sharpe_ratio:.2f}")

"""#Portfolio Backtesting

Compares the optimized portfolio performance against the Dow Jones Industrial Average (DJI)
Calculates various performance metrics including returns, volatility, alpha, and beta
Visualizes portfolio performance over time
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Define the stocks and their respective weights in the portfolio
weights = {
    "RELIANCE.NS": 0.15, "TCS.NS": 0.10, "INFY.NS": 0.10, "HDFCBANK.NS": 0.10,
    "ICICIBANK.NS": 0.08, "HINDUNILVR.NS": 0.07, "SBIN.NS": 0.07, "BAJFINANCE.NS": 0.07,
    "BHARTIARTL.NS": 0.06, "ITC.NS": 0.05, "LT.NS": 0.05, "AXISBANK.NS": 0.04,
    "ONGC.NS": 0.03, "SUNPHARMA.NS": 0.03, "WIPRO.NS": 0.02
}

# Initial investment
initial_investment = 100000

# Download historical data for the stocks and Nifty 50 as a benchmark
tickers = list(weights.keys()) + ['^NSEI']
data = yf.download(tickers, start="2021-8-1", end="2024-8-1")['Adj Close']

# Separate the benchmark data
benchmark_data = data.pop('^NSEI')

# Calculate daily returns for the stocks and the benchmark
returns = data.pct_change()
benchmark_returns = benchmark_data.pct_change()

# Calculate portfolio daily returns
portfolio_daily_returns = (returns * pd.Series(weights)).sum(axis=1)

# Calculate cumulative portfolio returns and benchmark returns
cumulative_portfolio_returns = (1 + portfolio_daily_returns).cumprod()
cumulative_benchmark_returns = (1 + benchmark_returns).cumprod()

# Calculate final portfolio value and benchmark value
final_portfolio_value = initial_investment * cumulative_portfolio_returns
final_benchmark_value = initial_investment * cumulative_benchmark_returns

# Calculate annual returns and Sharpe ratio for both portfolio and benchmark
annual_returns = portfolio_daily_returns.resample('Y').apply(lambda x: (1 + x).prod() - 1)
annual_benchmark_returns = benchmark_returns.resample('Y').apply(lambda x: (1 + x).prod() - 1)
annual_volatility = portfolio_daily_returns.resample('Y').std() * np.sqrt(252)
annual_benchmark_volatility = benchmark_returns.resample('Y').std() * np.sqrt(252)
risk_free_rate = 0.03  # Assume a risk-free rate of 3%
annual_sharpe_ratios = (annual_returns - risk_free_rate) / annual_volatility
annual_benchmark_sharpe = (annual_benchmark_returns - risk_free_rate) / annual_benchmark_volatility

# Calculate Beta and Alpha for the portfolio
covariance = np.cov(portfolio_daily_returns[1:], benchmark_returns[1:])
beta = covariance[0, 1] / covariance[1, 1]
alpha = annual_returns.mean() - (risk_free_rate + beta * (annual_benchmark_returns.mean() - risk_free_rate))

# Calculate and print excess returns for holding periods of 1, 2, 3, 4, and 5 years
holding_periods = [1, 2, 3, 4, 5]
for period in holding_periods:
    if len(final_portfolio_value) > period * 252:
        portfolio_period_return = final_portfolio_value[-1] / final_portfolio_value[-(period * 252)] - 1
        benchmark_period_return = final_benchmark_value[-1] / final_benchmark_value[-(period * 252)] - 1
        excess_return = portfolio_period_return - benchmark_period_return
        print(f"{period}-year Holding Period: Portfolio Return: {portfolio_period_return * 100:.2f}%, Benchmark Return: {benchmark_period_return * 100:.2f}%, Excess Return: {excess_return * 100:.2f}%")

# Print annual metrics for portfolio and benchmark
print("\nAnnual Returns and Sharpe Ratios:")
for year in sorted(annual_returns.index.year):
    print(f"{year} - Portfolio Return: {annual_returns[str(year)].mean() * 100:.2f}%, Sharpe Ratio: {annual_sharpe_ratios[str(year)].mean():.2f}")
    print(f"{year} - Benchmark Return: {annual_benchmark_returns[str(year)].mean() * 100:.2f}%, Sharpe Ratio: {annual_benchmark_sharpe[str(year)].mean():.2f}")

# Extract date range for plotting
start_date = final_portfolio_value.index.min().strftime('%Y-%m-%d')
end_date = final_portfolio_value.index.max().strftime('%Y-%m-%d')

# Plot both the portfolio and benchmark growth over time
plt.figure(figsize=(14, 7))
plt.plot(final_portfolio_value, label='Portfolio Value')
plt.plot(final_benchmark_value, color='red', label='Nifty 50 Index')
plt.title(f'Portfolio and Benchmark Value Over Time\n({start_date} to {end_date})')
plt.xlabel('Date')
plt.ylabel('Value in $')
plt.legend()
plt.grid(True)
plt.show()

# Calculate and print the final Sharpe ratio of the portfolio
final_annual_return = (final_portfolio_value[-1] / initial_investment) ** (1 / (len(final_portfolio_value) / 252)) - 1
final_annual_volatility = portfolio_daily_returns.std() * np.sqrt(252)
final_sharpe_ratio = (final_annual_return - risk_free_rate) / final_annual_volatility

# Print portfolio and benchmark metrics
print("\nPortfolio vs. Benchmark Metrics:")
print(f"Portfolio Beta: {beta:.2f}")
print(f"Portfolio Alpha: {alpha * 100:.2f}%")
print(f"Final portfolio value (end of period): ${final_portfolio_value.iloc[-1]:,.2f}")
print(f"Final benchmark value (end of period): ${final_benchmark_value.iloc[-1]:,.2f}")
print(f"Final Portfolio Sharpe Ratio: {final_sharpe_ratio:.2f}")